{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a1141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from grid import grid_world, Grid, print_values\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcdba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9    # discount factor\n",
    "theta = 0.1   # convergence threshold for policy evaluation\n",
    "\n",
    "actions = [\"up\", \"down\", \"left\", \"right\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd2de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grid_world()\n",
    "print(\"Grid World:\")\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9635ba",
   "metadata": {},
   "source": [
    "Setting random policy π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e59d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = (3, 3)  # goal state\n",
    "policy = Grid.generate_random_policy(grid, goal)\n",
    "print(\"Initial Random Policy:\")\n",
    "print(policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c88abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f99c9a",
   "metadata": {},
   "source": [
    "Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ae2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(grid, policy, gamma=1, theta=0.1):\n",
    "\n",
    "    # value dict\n",
    "    V = {state: 0.0 for state in grid.actions}\n",
    "    iter = 0\n",
    "    # print(\"Initial Value Function:\")\n",
    "    # print_values(V, grid)\n",
    "    converged = False\n",
    "    while not converged:\n",
    "        # print(f\"\\nIteration {iter}\")\n",
    "        delta = 0\n",
    "        for s in grid.actions:\n",
    "            if grid.is_terminal(s):\n",
    "                continue\n",
    "            action = policy[s]\n",
    "            next_state = grid.take_action(s, action)\n",
    "            reward = grid.rewards.get(s, 0)\n",
    "            # P(s'|s,a) = 1, so we ignore it\n",
    "            new_val = reward + gamma * V.get(next_state, 0)\n",
    "            delta = max(delta, abs(V[s] - new_val))\n",
    "            \n",
    "            # print_values(V, grid)\n",
    "        if delta < theta:\n",
    "            converged = True\n",
    "        iter += 1\n",
    "    # print(\"Value Function after Policy Evaluation:\")\n",
    "    # print_values(V, grid)\n",
    "    return V\n",
    "\n",
    "    \n",
    "\n",
    "# policy_evaluation(grid, policy, gamma, theta)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75da09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169c39c5",
   "metadata": {},
   "source": [
    "Policy Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9726b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(grid, V, gamma):\n",
    "    improved_policy = {}\n",
    "    # print(\"\\n--- Improving Policy ---\")\n",
    "    for s in grid.actions:\n",
    "        if grid.is_terminal(s):\n",
    "            continue\n",
    "        best_action = None\n",
    "        best_val = float(\"-inf\")\n",
    "        # print(f\"\\nEvaluating actions for state {s}:\")\n",
    "        for a in actions:\n",
    "            next_state = grid.take_action(s, a)\n",
    "            reward = grid.rewards.get(s, 0)\n",
    "            val = reward + gamma * V.get(next_state, 0)\n",
    "            # print(f\"  Action {a} → next state {next_state}, value = {val:.2f}\")\n",
    "\n",
    "            if val > best_val:\n",
    "                best_val = val\n",
    "                best_action = a\n",
    "        improved_policy[s] = best_action\n",
    "        # print(f\"  → Best action: {best_action} with value {best_val:.2f}\")\n",
    "\n",
    "\n",
    "    print(\"\\nImproved Policy:\")\n",
    "    for s in grid.actions:\n",
    "        if s in improved_policy:\n",
    "            print(f\"  State {s}: {improved_policy[s]}\")\n",
    "    return improved_policy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = policy_evaluation(grid, policy, gamma, theta)\n",
    "new_policy = policy_improvement(grid, V, gamma)\n",
    "grid.print_policy(new_policy, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713c2fa",
   "metadata": {},
   "source": [
    "Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd9b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    V = policy_evaluation(grid, policy, gamma, theta)\n",
    "\n",
    "    new_policy = policy_improvement(grid, V, gamma)\n",
    "\n",
    "    if new_policy == policy:\n",
    "        print(\"\\nPolicy is stable. Final Policy:\")\n",
    "        grid.print_policy(new_policy, grid)\n",
    "        break\n",
    "        \n",
    "        \n",
    "    policy = new_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc291100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94253c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
